{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "id": "W4WCO_fOzqxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ZJMXeJNn0j4"
      },
      "outputs": [],
      "source": [
        "# importing required libraries for extracting text from the PDF\n",
        "import PyPDF2\n",
        "import os\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading pdf\n",
        "uploaded  = files.upload()\n",
        "safety_manual = next(iter(uploaded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "VvHdSY1Zzi9c",
        "outputId": "127cced7-4854-4755-cf21-c6b986c4f34f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f3cb10aa-fd46-409c-a8cb-8fdcc2ea0bb8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f3cb10aa-fd46-409c-a8cb-8fdcc2ea0bb8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ADM_04-00-003.pdf to ADM_04-00-003.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extractin text from the PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  text = \"\"\n",
        "  with open(pdf_path, 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    num_pages = len(reader.pages)\n",
        "    for page_num in range(num_pages):\n",
        "      page = reader.pages[page_num]\n",
        "      text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(safety_manual)\n",
        "\n",
        "print(f'Extracted {len(pdf_text)} characters from the PDF')\n",
        "print(\"First 500 Characters!\")\n",
        "print(pdf_text[:500] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeMCk42Y0VuP",
        "outputId": "910b83fb-0f14-4758-e5da-eec2f98366d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 582028 characters from the PDF\n",
            "First 500 Characters!\n",
            " \n",
            " Abstract - 1 \n",
            " \n",
            " \n",
            "OSHA Field  \n",
            " Safety and Health  \n",
            "Manual\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "* OSHA ARCHIVE DOCUMENT * \n",
            "NOTICE: This is an OSHA ARCHIVE Document, and may no longer represent OSHA policy.\n",
            "* OSHA ARCHIVE DOCUMENT * \n",
            "NOTICE: This document is presented here as historical content, for research and review purposes only. \n",
            " Abstract - 2  \n",
            "U.S. DDEPARTMENT OF LABOR  Occupational Safety and Health Administration  \n",
            " \n",
            "DIRECTIVE NUMBER: ADM 04-00-003 EFFECTIVE DATE:  5/06/ 2020  \n",
            "SUBJECT: OSHA Safety and He...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning text basically removing long spaces\n",
        "def clean_text(text):\n",
        "  cleaned_text = '\\n'.join([line.strip() for line in text.split('\\n') if line.strip()])\n",
        "\n",
        "  cleaned_text = ' '.join(cleaned_text.split())\n",
        "\n",
        "  return cleaned_text\n",
        "cleaned_text = clean_text(pdf_text)\n",
        "\n",
        "print(\"cleaned_text Sample\")\n",
        "print(cleaned_text[:500] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARUGeMqi3fcE",
        "outputId": "71947e2e-902c-4c45-ede7-d7883065e51b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_text Sample\n",
            "Abstract - 1 OSHA Field Safety and Health Manual * OSHA ARCHIVE DOCUMENT * NOTICE: This is an OSHA ARCHIVE Document, and may no longer represent OSHA policy. * OSHA ARCHIVE DOCUMENT * NOTICE: This document is presented here as historical content, for research and review purposes only. Abstract - 2 U.S. DDEPARTMENT OF LABOR Occupational Safety and Health Administration DIRECTIVE NUMBER: ADM 04-00-003 EFFECTIVE DATE: 5/06/ 2020 SUBJECT: OSHA Safety and Health Management System ABSTRACT Purpose: Th...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "buPM3Thc3klk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive semantic Chunking\n",
        "from langchain.text_splitter import(\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    MarkdownHeaderTextSplitter,\n",
        "    Language,\n",
        "    HTMLHeaderTextSplitter\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "b734thIi76X7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up text splitter function\n",
        "def setup_text_splitter():\n",
        "  return RecursiveCharacterTextSplitter(\n",
        "      separators = ['\\n\\n','\\n','. ',' ',''],\n",
        "      chunk_size = 1000,\n",
        "      chunk_overlap = 200,\n",
        "      length_function = len,\n",
        "      add_start_index = True\n",
        "  )\n",
        "text_splitter = setup_text_splitter()"
      ],
      "metadata": {
        "id": "Jvk8fRhx8r5n"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "qFv_4x3kIQpd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking with metadata preservation\n",
        "def langchain_chunk_text(text:str, source:str) -> List[Document]:\n",
        "  # langchain document\n",
        "  doc = Document(page_content=text, metadata={'source':source})\n",
        "\n",
        "  # split the document\n",
        "  chunks = text_splitter.split_documents([doc])\n",
        "\n",
        "  # metadata for each chunk\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    chunk.metadata.update({\n",
        "        \"chunk_id\" : f\"{source}_chunk_{i}\",\n",
        "        \"total_chunks\" : len(chunks),\n",
        "        \"chunk_num\" : i,\n",
        "        \"length\" : len(chunk.page_content)\n",
        "    })\n",
        "  return chunks\n",
        "\n",
        "langchain_chunks = langchain_chunk_text(cleaned_text, safety_manual)\n",
        "\n",
        "print(f\"Created {len(langchain_chunks)} chunks using langchain splitter\")\n",
        "print(\"sample chunk structure\")\n",
        "pprint(langchain_chunks[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXICStXr94vM",
        "outputId": "0f057ca2-ffaa-4417-9d16-0cb75c5915e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 717 chunks using langchain splitter\n",
            "sample chunk structure\n",
            "{'chunk_id': 'ADM_04-00-003.pdf_chunk_0',\n",
            " 'chunk_num': 0,\n",
            " 'length': 998,\n",
            " 'source': 'ADM_04-00-003.pdf',\n",
            " 'start_index': 0,\n",
            " 'total_chunks': 717}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing Quality of the chunks\n",
        "def analyze_langchain_chunks(chunks: List[Document]):\n",
        "\n",
        "    lengths = [len(c.page_content) for c in chunks]\n",
        "    avg_len = sum(lengths) / len(lengths)\n",
        "\n",
        "    print(\"\\nChunk Quality Analysis:\")\n",
        "    print(f\"Total chunks: {len(chunks)}\")\n",
        "    print(f\"Average length: {avg_len:.1f} chars\")\n",
        "    print(f\"Min length: {min(lengths)} chars\")\n",
        "    print(f\"Max length: {max(lengths)} chars\")\n",
        "\n",
        "    # Check for bad chunks (too short/long)\n",
        "    bad_chunks = [c for c in chunks if len(c.page_content) < 50 or len(c.page_content) > 1500]\n",
        "    print(f\"\\nFound {len(bad_chunks)} potentially problematic chunks\")\n",
        "\n",
        "    if bad_chunks:\n",
        "        print(\"\\nProblematic chunk examples:\")\n",
        "        for c in bad_chunks[:2]:\n",
        "            print(f\"\\nChunk {c.metadata['chunk_num']} (length: {len(c.page_content)}):\")\n",
        "            print(c.page_content[:100] + \"...\")\n",
        "\n",
        "analyze_langchain_chunks(langchain_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwx7TmVzJ7q7",
        "outputId": "f712374d-3c0f-4dde-c8e7-804e640e1384"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chunk Quality Analysis:\n",
            "Total chunks: 717\n",
            "Average length: 905.9 chars\n",
            "Min length: 128 chars\n",
            "Max length: 1000 chars\n",
            "\n",
            "Found 0 potentially problematic chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "OMyY0JSHLHBN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_safety_text(text: str) -> str:\n",
        "\n",
        "    # Preserve important section breaks\n",
        "    text = text.replace(\"WARNING:\", \"\\n\\nWARNING:\\n\\n\")\n",
        "    text = text.replace(\"CAUTION:\", \"\\n\\nCAUTION:\\n\\n\")\n",
        "    text = text.replace(\"NOTE:\", \"\\n\\nNOTE:\\n\\n\")\n",
        "\n",
        "    # Handle numbered procedures\n",
        "    text = re.sub(r'(\\d+\\. )', r'\\n\\n\\1', text)  # Ensure newlines before numbered items\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply specialized preprocessing\n",
        "preprocessed_text = preprocess_safety_text(cleaned_text)\n",
        "\n",
        "# Re-chunk with specialized preprocessing\n",
        "enhanced_chunks = langchain_chunk_text(preprocessed_text, safety_manual)\n",
        "\n",
        "print(\"\\nAfter specialized preprocessing:\")\n",
        "analyze_langchain_chunks(enhanced_chunks)\n",
        "\n",
        "# Explanation:\n",
        "# - Adds extra spacing around critical safety sections\n",
        "# - Better handles numbered procedures\n",
        "# - Results in more semantically meaningful chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVGPn5OLBbK",
        "outputId": "a9f578f8-532c-4d9e-d25d-5602a712a826"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After specialized preprocessing:\n",
            "\n",
            "Chunk Quality Analysis:\n",
            "Total chunks: 788\n",
            "Average length: 779.1 chars\n",
            "Min length: 5 chars\n",
            "Max length: 1000 chars\n",
            "\n",
            "Found 2 potentially problematic chunks\n",
            "\n",
            "Problematic chunk examples:\n",
            "\n",
            "Chunk 398 (length: 5):\n",
            "NOTE:...\n",
            "\n",
            "Chunk 618 (length: 5):\n",
            "NOTE:...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we get short chunks above we have 2 so we merge with next chunk\n",
        "def merge_short_chunks(chunks, min_len=20):\n",
        "    \"\"\"\n",
        "    Merge short chunks (like 'NOTE:') with the next chunk instead of deleting them.\n",
        "    \"\"\"\n",
        "    merged_chunks = []\n",
        "    i = 0\n",
        "    while i < len(chunks):\n",
        "        current_chunk = chunks[i]\n",
        "        current_text = current_chunk.page_content.strip()\n",
        "\n",
        "        # If the chunk is too short and looks like a header (e.g., \"NOTE:\")\n",
        "        if len(current_text) < min_len and current_text.upper() in [\"NOTE:\", \"CAUTION:\", \"WARNING:\"]:\n",
        "            if i + 1 < len(chunks):\n",
        "                # Merge with next chunk\n",
        "                next_chunk = chunks[i + 1]\n",
        "                merged_text = current_text + \" \" + next_chunk.page_content\n",
        "\n",
        "                # Create a new Document with merged text and updated metadata\n",
        "                merged_doc = Document(\n",
        "                    page_content=merged_text,\n",
        "                    metadata={\n",
        "                        **next_chunk.metadata,\n",
        "                        \"merged_with_previous\": True,\n",
        "                        \"chunk_id\": f\"{next_chunk.metadata['chunk_id']}_merged\",\n",
        "                        \"chunk_num\": next_chunk.metadata[\"chunk_num\"],\n",
        "                        \"length\": len(merged_text)\n",
        "                    }\n",
        "                )\n",
        "                merged_chunks.append(merged_doc)\n",
        "                i += 2  # Skip next chunk (already merged)\n",
        "            else:\n",
        "                # Last chunk, no one to merge with \u2014 keep it as-is\n",
        "                merged_chunks.append(current_chunk)\n",
        "                i += 1\n",
        "        else:\n",
        "            merged_chunks.append(current_chunk)\n",
        "            i += 1\n",
        "    return merged_chunks\n"
      ],
      "metadata": {
        "id": "AZGwwx8-NyhI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply merging after enhanced chunking\n",
        "final_chunks = merge_short_chunks(enhanced_chunks)\n",
        "\n",
        "# Re-analyze quality\n",
        "analyze_langchain_chunks(final_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHQJorLOEsm",
        "outputId": "f13379e7-bd22-461a-9667-ac81c240d998"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chunk Quality Analysis:\n",
            "Total chunks: 786\n",
            "Average length: 781.1 chars\n",
            "Min length: 57 chars\n",
            "Max length: 1000 chars\n",
            "\n",
            "Found 0 potentially problematic chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def prepare_for_pinecone(chunks: List[Document]) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Converts LangChain Documents to Pinecone-ready format.\n",
        "    \"\"\"\n",
        "    pinecone_records = []\n",
        "    for chunk in chunks:\n",
        "        record = {\n",
        "            \"id\": chunk.metadata[\"chunk_id\"],\n",
        "            \"text\": chunk.page_content,\n",
        "            \"metadata\": chunk.metadata\n",
        "        }\n",
        "        pinecone_records.append(record)\n",
        "    return pinecone_records\n",
        "\n",
        "pinecone_ready = prepare_for_pinecone(final_chunks)\n",
        "\n",
        "# Save to JSON\n",
        "with open('pinecone_ready_chunks.json', 'w') as f:\n",
        "    json.dump(pinecone_ready, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved {len(pinecone_ready)} Pinecone-ready chunks to 'pinecone_ready_chunks.json'\")\n",
        "\n",
        "# Explanation:\n",
        "# - Converts LangChain's Document format to Pinecone's expected structure\n",
        "# - Preserves all metadata\n",
        "# - Each record has: id, text, and metadata fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KddEpcRnNgrz",
        "outputId": "ab14e2e9-d9f5-4b95-c60f-7f579b484f34"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved 786 Pinecone-ready chunks to 'pinecone_ready_chunks.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers torch"
      ],
      "metadata": {
        "id": "8UjnIndKOnrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Embedding\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# Initialize device (use GPU if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the open-source model\n",
        "model = SentenceTransformer('BAAI/bge-small-en', device=device)\n",
        "\n",
        "# Test the model\n",
        "sentence = \"Sample safety instruction about fire extinguishers\"\n",
        "embedding = model.encode(sentence)\n",
        "\n",
        "print(\"\ud83d\udccc Embedded text:\")\n",
        "print(sentence)\n",
        "\n",
        "print(\"\\n\ud83d\udd22 Embedding (first 10 values):\")\n",
        "print(embedding[:10])  # Show first 10 dimensions\n",
        "\n",
        "print(f\"\\n\ud83d\udccf Total dimensions: {len(embedding)}\")\n",
        "\n",
        "# Explanation:\n",
        "# - BAAI/bge-small-en outperforms many paid models on benchmarks\n",
        "# - Runs locally (no API costs)\n",
        "# - Automatically uses GPU if available\n",
        "# - Fixed 384-dimension output (more efficient storage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFM8OomjQ2sp",
        "outputId": "6d356538-974c-497e-f2c7-468e41032642"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udccc Embedded text:\n",
            "Sample safety instruction about fire extinguishers\n",
            "\n",
            "\ud83d\udd22 Embedding (first 10 values):\n",
            "[-0.07474203  0.02710574  0.03077703 -0.07079734  0.02252393  0.03854874\n",
            "  0.03483909  0.0447201  -0.03685036 -0.01119724]\n",
            "\n",
            "\ud83d\udccf Total dimensions: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating embeddings in Batches\n",
        "def generate_embeddings(texts: list, batch_size=64) -> list:\n",
        "    \"\"\"Generate embeddings in optimized batches\"\"\"\n",
        "    return model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True  # Important for cosine similarity\n",
        "    )\n",
        "\n",
        "# Generate embeddings for all chunks\n",
        "chunk_texts = [chunk[\"text\"] for chunk in pinecone_ready]\n",
        "print(\"Generating embeddings with BGE model...\")\n",
        "chunk_embeddings = generate_embeddings(chunk_texts)\n",
        "\n",
        "# Add to our records\n",
        "for i, record in enumerate(pinecone_ready):\n",
        "    record[\"values\"] = chunk_embeddings[i].tolist()  # Convert numpy to list\n",
        "\n",
        "# Explanation:\n",
        "# - Batched processing optimized for GPU\n",
        "# - normalize_embeddings=True ensures proper cosine similarity\n",
        "# - Progress bar shows embedding generation status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "92cda5a8446d40c7a0a841bb2cef0e9b",
            "4b7c0b478eee450785aca3e776c4d0fd",
            "e2ea5a6ac4184faaa796550cb4a4c06e",
            "ef36a3a08c7345dfae83830b06bb00a8",
            "fdbd9011fd76419da23cadd8de4c398d",
            "3ebbb454bb4b48a4a68d18893cc0ba51",
            "469302f3389b48aca33f172686652010",
            "bb91635f89674f06ae8e375c5edc187d",
            "d2702ce315ce4375a4aa3a706fb0d70d",
            "b7765876a01242c3b40719eeace2d026",
            "cf9a6e5550304bc19799e9c4e187de54"
          ]
        },
        "id": "gM61do2EbLKz",
        "outputId": "898f424c-d071-4cf3-f04c-5de8ec472055"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings with BGE model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92cda5a8446d40c7a0a841bb2cef0e9b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\n\ud83d\udcc4 Text Chunk {i}:\\n{pinecone_ready[i]['text'][:150]}...\")  # Print first 150 chars\n",
        "    print(f\"\\n\ud83e\udde0 Embedding {i} (First 10 dims): {np.round(chunk_embeddings[i][:10], 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1gxvOwdj95",
        "outputId": "db20bec2-0426-4543-c557-5638dc25a0f2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udcc4 Text Chunk 0:\n",
            "Abstract - 1 OSHA Field Safety and Health Manual * OSHA ARCHIVE DOCUMENT * NOTICE: This is an OSHA ARCHIVE Document, and may no longer represent OSHA ...\n",
            "\n",
            "\ud83e\udde0 Embedding 0 (First 10 dims): [-0.0171 -0.0041  0.0272 -0.0251  0.0088  0.0061  0.0431  0.0405 -0.0433\n",
            "  0.0158]\n",
            "\n",
            "\ud83d\udcc4 Text Chunk 1:\n",
            ". It is the intent of this program that all employees will participate in all aspects including reporting hazards, incidents, and injury/illness witho...\n",
            "\n",
            "\ud83e\udde0 Embedding 1 (First 10 dims): [-0.0288  0.0092  0.0283 -0.0163 -0.0118  0.0475  0.0851  0.0242 -0.0675\n",
            " -0.0023]\n",
            "\n",
            "\ud83d\udcc4 Text Chunk 2:\n",
            ". Cancellations: OSHA Instruction ADM 04 -00-002, OSHA Field Safety and Health Manual, October 5, 2016 State Impact: None. For State reference only. A...\n",
            "\n",
            "\ud83e\udde0 Embedding 2 (First 10 dims): [-0.0152  0.0192  0.0625  0.034   0.0402 -0.0008  0.048   0.04   -0.0458\n",
            " -0.0187]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone (free tier)\n",
        "pc = Pinecone(api_key=\"pcsk_oRen9_PnQ5DEGXJ5K1Tap43YZ7AGn6p8rk2uweQzcePUjdgM9nsrdDBFpxjs81pTCn7YA\")\n",
        "\n",
        "INDEX_NAME = \"safety-manuals-bge\"\n",
        "\n",
        "# Delete if exists\n",
        "if INDEX_NAME in pc.list_indexes().names():\n",
        "    pc.delete_index(INDEX_NAME)\n",
        "\n",
        "# Create index with free-tier compatible settings\n",
        "pc.create_index(\n",
        "    name=INDEX_NAME,\n",
        "    dimension=384,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",  # Free tier only supports AWS\n",
        "        region=\"us-east-1\"  # Supported free tier region\n",
        "    )\n",
        ")\n",
        "\n",
        "index = pc.Index(INDEX_NAME)\n",
        "print(\"Index created successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OutsCuhBedtZ",
        "outputId": "1429d99a-1db5-4404-c8c3-658e5eebb396"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index created successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "\n",
        "def prepare_upsert_data(chunks_with_metadata, embeddings):\n",
        "    \"\"\"Prepare data for upsert in Pinecone format\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"id\": chunk[\"id\"],\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": {**chunk[\"metadata\"], \"text\": chunk[\"text\"]}  # \u2705 Include text\n",
        "        }\n",
        "        for chunk, embedding in zip(chunks_with_metadata, embeddings)\n",
        "    ]\n",
        "\n",
        "# Prepare the upsert data\n",
        "upsert_data = prepare_upsert_data(pinecone_ready, chunk_embeddings)\n",
        "\n",
        "# Upload in batches with progress tracking\n",
        "BATCH_SIZE = 100  # Pinecone\u2019s recommended max\n",
        "total_batches = math.ceil(len(upsert_data) / BATCH_SIZE)\n",
        "\n",
        "print(f\"Uploading {len(upsert_data)} vectors in {total_batches} batches...\")\n",
        "\n",
        "with tqdm(total=len(upsert_data), desc=\"Uploading vectors\") as pbar:\n",
        "    for i in range(0, len(upsert_data), BATCH_SIZE):\n",
        "        batch = upsert_data[i:i + BATCH_SIZE]\n",
        "        index.upsert(vectors=batch)\n",
        "        pbar.update(len(batch))\n",
        "\n",
        "# Verify upload\n",
        "stats = index.describe_index_stats()\n",
        "print(\"\\n\u2705 Upload complete!\")\n",
        "print(f\"\ud83d\udccc Total vectors: {stats['total_vector_count']}\")\n",
        "print(f\"\ud83d\udccf Index dimension: {stats['dimension']}\")\n",
        "print(f\"\ud83d\udcca Index fullness: {stats['index_fullness']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "a2461d838562489f91ac1737e51ed84f",
            "2d3b591c497e47ec834d7faf5b6fa829",
            "be107cbd6e6146d19ab22fd9aef11558",
            "60f28ecb04ed4fe5b598e85bddaf0244",
            "44ec7299f8d94f6baee5b884f0a3ffea",
            "9e9188cc309b49b38549aff289b85c85",
            "50cf1ffa34c04b7d81f98ec1831973e3",
            "d3f4411d66304aa9bd43cece037cd581",
            "578ab1b1c08f455e9085a17e2f5e8795",
            "0c9b7312911a446f875df1996a4d12d5",
            "48045c27857440f7983c02bcedfcc54d"
          ]
        },
        "id": "qFU2B3YKjB61",
        "outputId": "e5344519-da8f-4187-eba5-b400cae99f28"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading 786 vectors in 8 batches...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading vectors:   0%|          | 0/786 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2461d838562489f91ac1737e51ed84f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u2705 Upload complete!\n",
            "\ud83d\udccc Total vectors: 0\n",
            "\ud83d\udccf Index dimension: 384\n",
            "\ud83d\udcca Index fullness: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index description to understand default configuration\n",
        "index_description = pc.describe_index(INDEX_NAME)\n",
        "print(\"Index Configuration:\")\n",
        "print(f\"Name: {index_description.name}\")\n",
        "print(f\"Dimension: {index_description.dimension}\")\n",
        "print(f\"Metric: {index_description.metric}\")\n",
        "print(f\"Spec: {index_description.spec}\")\n",
        "print(f\"Status: {index_description.status.state}\")\n",
        "\n",
        "# Explanation:\n",
        "# - Serverless indexes automatically handle HNSW configuration\n",
        "# - Pinecone optimizes these parameters based on usage patterns\n",
        "# - We can influence performance through query-time parameters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j6Cx7vPjMEL",
        "outputId": "f10859f0-1431-44a5-b69b-4b065b072c08"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index Configuration:\n",
            "Name: safety-manuals-bge\n",
            "Dimension: 384\n",
            "Metric: cosine\n",
            "Spec: {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}}\n",
            "Status: Ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimized_query(query: str, top_k: int = 5, filters: dict = None):\n",
        "    \"\"\"\n",
        "    Perform optimized query with serverless index best practices.\n",
        "\n",
        "    Args:\n",
        "        query: Natural language search string\n",
        "        top_k: Number of results to return\n",
        "        filters: Optional metadata filters (e.g., by source)\n",
        "\n",
        "    Returns:\n",
        "        List of top matching vectors with scores and metadata\n",
        "    \"\"\"\n",
        "    # Generate embedding for query\n",
        "    query_embedding = model.encode(query, normalize_embeddings=True).tolist()\n",
        "\n",
        "    # Run query\n",
        "    results = index.query(\n",
        "        vector=query_embedding,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        filter=filters,\n",
        "        include_values=False,\n",
        "        ef_search=100  # Balances recall vs latency (recommended for serverless)\n",
        "    )\n",
        "\n",
        "    return results.matches\n"
      ],
      "metadata": {
        "id": "MVIwyMj6joSE"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_and_display(query_text: str, top_k: int = 3):\n",
        "    \"\"\"\n",
        "    Performs semantic search on Pinecone and prints top results.\n",
        "\n",
        "    Args:\n",
        "        query_text (str): The question or search phrase.\n",
        "        top_k (int): Number of top results to return.\n",
        "    \"\"\"\n",
        "    results = optimized_query(query_text, top_k=top_k)\n",
        "\n",
        "    print(f\"\\n\ud83d\udd0d Query: \\\"{query_text}\\\"\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    for idx, match in enumerate(results, 1):\n",
        "        print(f\"\\n\ud83d\udd39 Result {idx}\")\n",
        "        print(f\"\ud83d\udccc Score: {match.score:.3f}\")\n",
        "        print(f\"\ud83d\udcc4 Source: {match.metadata.get('source', '[No source]')}\")\n",
        "        print(f\"\ud83d\udcdd Content Preview:\\n{match.metadata.get('text', '[No text]')[:300]}...\\n{'-'*60}\")\n"
      ],
      "metadata": {
        "id": "DkHVvM0xssyn"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"What PPE is required for field inspection?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZSWLPDluAdp",
        "outputId": "1f965751-9941-435c-f6a7-b0bd8b539db2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"What PPE is required for field inspection?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.880\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "1. At the start of any inspection/audit or other field activity, the employees will assess the need for PPE, which will include the employer\u2019s PPE assessment. \n",
            "\n",
            "2. Employees including temporary, contract and visiting employees will abide by OSHA\u2019s PPE Program (Chapter 8) or the program of the employ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.876\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "1. Wear PPE as necessary; \n",
            "\n",
            "2. Attend PPE training sessions; \n",
            "\n",
            "3. Care for, clean, maintain and dispose of PPE as necessary; and \n",
            "\n",
            "4. Report any damaged or defective PPE to their responsible OSHA Manager(s). IV. Procedure Hazard Assessment \n",
            "\n",
            "1. Based on a general assessment of all work sites, it is ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.870\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "4. Maintain training records, as well as electrical field testing equipment and PPE records. \n",
            "\n",
            "5. Provide appropriate PPE and make it available to employees (see Appendix A). \n",
            "\n",
            "6. Provide appropriate and approved electrical testing equipment for employee use. \n",
            "\n",
            "7. Ensure that PPE and electrical test...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"What are the roles and responsibilities of a Regional Administrator?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2orpT6uuNhC",
        "outputId": "e7ad9829-d50a-48f6-867a-cd3b3dbb531a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"What are the roles and responsibilities of a Regional Administrator?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.897\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "3. Regional Offices The Regional Administrator s bear responsibility for the health and safety of all Regional employees as well as temporary, contract and visiting employees . The Regional Administrat or will demonstrate leadership and commitment to employee safety and health. See Chapter 4 for rol...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.894\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "4. REGIONAL OFFICE I. Roles and Responsibilities The Regional Administrator will: \n",
            "\n",
            "1. Implement the SHMS and safety and health programs in accordance with this Instruction and existing laws and regulations applicable to all working conditions of employees in the Region. \n",
            "\n",
            "2. Serve as a role model t...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.873\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "6. Ensuring that any problems or discrepancies in the administration of the hearing conservation program are resolved. Regional Administrators, and Directorate Heads The Regional Administrators and Directorate Heads (as appropriate) shall ensure the overall administration of the HCP on regional, loc...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"How are safety hazards supposed to be reported by employees?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuuWOht2uWWu",
        "outputId": "18ed81dc-204e-4299-fde5-cba405e6aa2e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"How are safety hazards supposed to be reported by employees?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.900\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". d. Identify other site -specific hazards and how to protect Authorized Employees (e .g. noise, electricity). Determine if employees with specialized expertise to mitigate specific hazards are needed, for example, to verify proper lockout/tagout of hazardous energy sources and proper Radio Frequenc...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.895\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "1. Hazards and risks to employees' safety and health should be identified and assessed on an ongoing basis at b oth the office and field locations, such as at enforcement inspection and VPP onsite evaluation locations. Implementation of preventive and protective measures should: eliminate the hazard...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.888\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "5. Reports of unsafe conditions may also be submitted to any local management or the Department of Labor on line using DL 1 -1097 Form, Reporting Unsafe and Unhealthful Conditions located at https://shimshosting.dol.gov/login/ShimsLogin.aspx ). Rep orts may be submitted anonymously. The Office of th...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"What training requirements must supervisors follow?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBFcA7lruXLv",
        "outputId": "e05c7d53-c1c7-4c26-dc7f-82e933175eb4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"What training requirements must supervisors follow?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.886\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". 2-11 Records of training will be maintained for th ree years at the Regional or Office level to ensure that all employees have been appropriately trained. Supervisors (or designees) will make available records of the training conducted to the Regional Administrator, and DTSEM when requested. Super...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.873\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "4. Supervisors will periodically evaluate the employee use of PPE to ensure that employees are adequately protected. VI. Safety and Health Training The following procedures apply to supervisors (or designees) in the Regions: The supervisor (or designee) will ensure that all employees are trained ini...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.863\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "7. Assure employees have input into the program and that annual goals are communicated to all employees. \n",
            "\n",
            "8. Be aware of and use safety and health resources available to meet the occupational safety and health needs within their jurisdiction. \n",
            "\n",
            "9. Provide timely reports including annual SHMS evalua...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"Explain the corrective action tracking process after a hazard report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjV-23HFuXle",
        "outputId": "61ea0b6d-c986-4a73-ae94-8d9b5946e74c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"Explain the corrective action tracking process after a hazard report.\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.883\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". 2-10 VII. SPECIFIC SAFETY AND HEALTH PROGRAMS ................................ ................................ .... 2-11 APPENDIX A: CORRECTIVE ACTIONS LIST ................................ ................................ .............. 2-12 APPENDIX B : HAZARD REPORTING AND INCIDENT INVESTIGATI...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.882\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "2. Describe the procedures to oversee the activities of service / nested contractors who perform work in your office or building. B-\n",
            "\n",
            "3. Accident/Incident I nvestigations * OSHA ARCHIVE DOCUMENT * NOTICE: This is an OSHA ARCHIVE Document, and may no longer represent OSHA policy. * OSHA ARCHIVE DOCUM...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.880\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". Completed Incident Investigation and Hazard Reporting Worksheet (Reporting Worksheet) are sent to the RSHM within five days of the incident correction due date. Copies are kept at the office for employees to review. V. Hazard Prevention and Control Hazard prevention and control procedures must be ...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"What is included in the SHMS self-evaluation process?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbWSDUwBuYHT",
        "outputId": "9aece62c-372b-4e4d-cb18-37e375423252"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"What is included in the SHMS self-evaluation process?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.887\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "15. e. The Regional Office will receive copies of the latest Annual SHMS Self -Evaluation from the Area and District Offices. By February 15 of each year, the RSHM will review the Annual SHMS Self -Evaluations from each Area and D istrict Office, then summarize and brief the Regional Administrator a...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.880\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". h. The RSHM will share general summaries of the Annual SHMS Self -Evaluations with the RSHC. A copy of the Annual SHMS Self -Evaluation must be forwarded to DTSEM. * OSHA ARCHIVE DOCUMENT * NOTICE: This is an OSHA ARCHIVE Document, and may no longer represent OSHA policy. * OSHA ARCHIVE DOCUMENT *...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.874\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "2. Facilitate and review Regional, Area, and District Office Annual SHMS Self -Evaluations. a. By December 15 the RSHM will send the Area Director and the NCFLL R epresentative of each Area Office instructions * OSHA ARCHIVE DOCUMENT * NOTICE: This is an OSHA ARCHIVE Document, and may no longer repr...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"How is the SHMS changed and who approves it?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmctSLk2uYfA",
        "outputId": "4e5d1b39-1cdd-44d5-831a-454b14a8581e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"How is the SHMS changed and who approves it?\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.886\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". Changes related to the implementation of SHMS may be made with local SHMS committee approval. Changes to the SHMS or programs that alter SHMS or program policies require National Labor -Management Steering Committee review and approval. The SHMS and its programs will be implemented in phases per t...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.866\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". The SHMS and programs provide baseline guidance to OSHA in order to implement an effective SHMS to prevent employee injuries, illnesses and fatalities. Within established guidelines, Regional Administrators may suppleme nt or augment the SHMS and programs to address the unique needs within the Nat...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.864\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            ". These may be supplemented or augmented to enhance employee safety and health. Safety and health on additional topics may also be adopted and implemented to address unique safety and health topics. All safety and health programs shall ensure the highest level of protection for employees, temporary ...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_display(\"Describe the requirements for PPE during field inspections.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tUjCkVtuY-_",
        "outputId": "b3030e4b-4f24-4b0b-d44a-a23b99ab2481"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd0d Query: \"Describe the requirements for PPE during field inspections.\"\n",
            "============================================================\n",
            "\n",
            "\ud83d\udd39 Result 1\n",
            "\ud83d\udccc Score: 0.898\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "1. At the start of any inspection/audit or other field activity, the employees will assess the need for PPE, which will include the employer\u2019s PPE assessment. \n",
            "\n",
            "2. Employees including temporary, contract and visiting employees will abide by OSHA\u2019s PPE Program (Chapter 8) or the program of the employ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 2\n",
            "\ud83d\udccc Score: 0.893\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "1. Wear PPE as necessary; \n",
            "\n",
            "2. Attend PPE training sessions; \n",
            "\n",
            "3. Care for, clean, maintain and dispose of PPE as necessary; and \n",
            "\n",
            "4. Report any damaged or defective PPE to their responsible OSHA Manager(s). IV. Procedure Hazard Assessment \n",
            "\n",
            "1. Based on a general assessment of all work sites, it is ...\n",
            "------------------------------------------------------------\n",
            "\n",
            "\ud83d\udd39 Result 3\n",
            "\ud83d\udccc Score: 0.889\n",
            "\ud83d\udcc4 Source: ADM_04-00-003.pdf\n",
            "\ud83d\udcdd Content Preview:\n",
            "4. Maintain training records, as well as electrical field testing equipment and PPE records. \n",
            "\n",
            "5. Provide appropriate PPE and make it available to employees (see Appendix A). \n",
            "\n",
            "6. Provide appropriate and approved electrical testing equipment for employee use. \n",
            "\n",
            "7. Ensure that PPE and electrical test...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def clean_widgets_from_notebook(input_path, output_path):\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        notebook = json.load(f)\n",
        "\n",
        "    if 'widgets' in notebook.get('metadata', {}):\n",
        "        print(\"\ud83e\uddf9 Removing corrupted widget metadata...\")\n",
        "        del notebook['metadata']['widgets']\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(notebook, f, indent=2)\n",
        "\n",
        "    print(f\"\u2705 Cleaned notebook saved to: {output_path}\")\n",
        "\n",
        "# Example usage:\n",
        "clean_widgets_from_notebook(\"vectorsLearning.ipynb\", \"vectorsLearning_clean.ipynb\")\n"
      ],
      "metadata": {
        "id": "8vu4yKCxxmsT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}