{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJylI0aHCy8f3Vx3TX88v8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsha-9977/AIML/blob/main/happy_voice_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKoIX7g69yUB",
        "outputId": "533ae81f-2cfa-4687-be08-db6acce63ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip\n",
        "!unzip -q Audio_Speech_Actors_01-24.zip -d ravdess_speech\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2d7rchn-R1D",
        "outputId": "16428c4e-b60d-4611-f8b8-af7b51f6e73d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip\n",
            "To: /content/Audio_Speech_Actors_01-24.zip\n",
            "100% 208M/208M [03:02<00:00, 1.14MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=22050, mono=True, duration=4)\n",
        "    if len(y) < sr * 4:\n",
        "        y = np.pad(y, (0, sr * 4 - len(y)))\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "    melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
        "\n",
        "    if melspec_db.shape[1] < 128:\n",
        "        melspec_db = np.pad(melspec_db, ((0, 0), (0, 128 - melspec_db.shape[1])), mode='constant')\n",
        "    else:\n",
        "        melspec_db = melspec_db[:, :128]\n",
        "\n",
        "    melspec_db = (melspec_db - melspec_db.min()) / (melspec_db.max() - melspec_db.min() + 1e-6)\n",
        "    return melspec_db[..., np.newaxis]  # Shape: (128, 128, 1)\n"
      ],
      "metadata": {
        "id": "bYxTLC8I-Skq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "emotion_map = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",      # our target\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for actor in sorted(os.listdir(\"ravdess_speech\")):\n",
        "    actor_path = os.path.join(\"ravdess_speech\", actor)\n",
        "    for file in tqdm(os.listdir(actor_path), desc=f\"Processing {actor}\"):\n",
        "        if file.endswith(\".wav\"):\n",
        "            emotion_id = file.split(\"-\")[2]\n",
        "            label = 1 if emotion_map[emotion_id] == \"happy\" else 0\n",
        "            path = os.path.join(actor_path, file)\n",
        "            features = extract_features(path)\n",
        "            X.append(features)\n",
        "            y.append(label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(\"✅ Dataset prepared:\", X.shape, y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUte_cIN-gi6",
        "outputId": "601255a0-b4da-4d78-bf6b-e08255bedc6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Actor_01: 100%|██████████| 60/60 [00:23<00:00,  2.56it/s]\n",
            "Processing Actor_02: 100%|██████████| 60/60 [00:01<00:00, 59.55it/s]\n",
            "Processing Actor_03: 100%|██████████| 60/60 [00:00<00:00, 60.58it/s]\n",
            "Processing Actor_04: 100%|██████████| 60/60 [00:00<00:00, 62.11it/s]\n",
            "Processing Actor_05: 100%|██████████| 60/60 [00:01<00:00, 49.06it/s]\n",
            "Processing Actor_06: 100%|██████████| 60/60 [00:03<00:00, 19.91it/s]\n",
            "Processing Actor_07: 100%|██████████| 60/60 [00:01<00:00, 34.17it/s]\n",
            "Processing Actor_08: 100%|██████████| 60/60 [00:01<00:00, 58.44it/s]\n",
            "Processing Actor_09: 100%|██████████| 60/60 [00:01<00:00, 54.39it/s]\n",
            "Processing Actor_10: 100%|██████████| 60/60 [00:00<00:00, 61.38it/s]\n",
            "Processing Actor_11: 100%|██████████| 60/60 [00:00<00:00, 62.25it/s]\n",
            "Processing Actor_12: 100%|██████████| 60/60 [00:00<00:00, 61.26it/s]\n",
            "Processing Actor_13: 100%|██████████| 60/60 [00:01<00:00, 46.78it/s]\n",
            "Processing Actor_14: 100%|██████████| 60/60 [00:01<00:00, 38.45it/s]\n",
            "Processing Actor_15: 100%|██████████| 60/60 [00:01<00:00, 54.91it/s]\n",
            "Processing Actor_16: 100%|██████████| 60/60 [00:01<00:00, 37.28it/s]\n",
            "Processing Actor_17: 100%|██████████| 60/60 [00:03<00:00, 18.93it/s]\n",
            "Processing Actor_18: 100%|██████████| 60/60 [00:03<00:00, 19.29it/s]\n",
            "Processing Actor_19: 100%|██████████| 60/60 [00:02<00:00, 26.45it/s]\n",
            "Processing Actor_20: 100%|██████████| 60/60 [00:01<00:00, 57.99it/s]\n",
            "Processing Actor_21: 100%|██████████| 60/60 [00:01<00:00, 57.75it/s]\n",
            "Processing Actor_22: 100%|██████████| 60/60 [00:01<00:00, 55.55it/s]\n",
            "Processing Actor_23: 100%|██████████| 60/60 [00:00<00:00, 60.75it/s]\n",
            "Processing Actor_24: 100%|██████████| 60/60 [00:01<00:00, 58.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset prepared: (1440, 128, 128, 1) (1440,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
        "                    validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgLlDtDD-k4p",
        "outputId": "216a0733-d6d9-4bfb-caaa-63b53585a8d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.8115 - loss: 0.4655 - val_accuracy: 0.8785 - val_loss: 0.3761\n",
            "Epoch 2/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 954ms/step - accuracy: 0.8728 - loss: 0.3929 - val_accuracy: 0.8785 - val_loss: 0.3662\n",
            "Epoch 3/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 994ms/step - accuracy: 0.8513 - loss: 0.4311 - val_accuracy: 0.8785 - val_loss: 0.3635\n",
            "Epoch 4/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.8681 - loss: 0.3940 - val_accuracy: 0.8785 - val_loss: 0.3556\n",
            "Epoch 5/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 947ms/step - accuracy: 0.8678 - loss: 0.3781 - val_accuracy: 0.8785 - val_loss: 0.3390\n",
            "Epoch 6/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 960ms/step - accuracy: 0.8479 - loss: 0.4144 - val_accuracy: 0.8785 - val_loss: 0.3483\n",
            "Epoch 7/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 992ms/step - accuracy: 0.8700 - loss: 0.3603 - val_accuracy: 0.8785 - val_loss: 0.3239\n",
            "Epoch 8/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 968ms/step - accuracy: 0.8730 - loss: 0.3454 - val_accuracy: 0.8785 - val_loss: 0.3185\n",
            "Epoch 9/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8666 - loss: 0.3302 - val_accuracy: 0.8785 - val_loss: 0.3211\n",
            "Epoch 10/10\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 921ms/step - accuracy: 0.8728 - loss: 0.3030 - val_accuracy: 0.8889 - val_loss: 0.2984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"✅ Test Accuracy: {test_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoxGIved-pHI",
        "outputId": "76bfee74-8cc1-429c-9c02-0c576518bd4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8836 - loss: 0.3222\n",
            "✅ Test Accuracy: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save in Colab\n",
        "model.save(\"happy_speech_classifier.h5\")\n",
        "\n",
        "# Optional: Save to Google Drive\n",
        "model.save(\"/content/drive/MyDrive/happy_speech_classifier.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWNpIymV-qXQ",
        "outputId": "30512f91-f078-4a4f-e2f2-d4ee9319dfdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# Create a happy sample (higher frequency)\n",
        "happy_audio = np.sin(2 * np.pi * 880 * np.linspace(0, 1, 44100))\n",
        "sf.write('happy_sample.wav', happy_audio, 44100)\n",
        "\n",
        "# Create a sad sample (lower frequency)\n",
        "sad_audio = np.sin(2 * np.pi * 220 * np.linspace(0, 1, 44100))\n",
        "sf.write('not_happy_sample.wav', sad_audio, 44100)"
      ],
      "metadata": {
        "id": "wa2ddz4fBAL3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_audio(filename):\n",
        "    try:\n",
        "        y, sr = librosa.load(filename, sr=22050, mono=True, duration=4.0)\n",
        "        if len(y) < sr * 4:\n",
        "            y = np.pad(y, (0, sr * 4 - len(y)))\n",
        "\n",
        "        melspec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "        melspec_db = librosa.power_to_db(melspec, ref=np.max)\n",
        "\n",
        "        if melspec_db.shape[1] < 128:\n",
        "            melspec_db = np.pad(melspec_db, ((0, 0), (0, 128 - melspec_db.shape[1])), mode='constant')\n",
        "        else:\n",
        "            melspec_db = melspec_db[:, :128]\n",
        "\n",
        "        melspec_db = (melspec_db - np.min(melspec_db)) / (np.max(melspec_db) - np.min(melspec_db) + 1e-6)\n",
        "        input_data = melspec_db[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "        prob = model.predict(input_data, verbose=0)[0][0]\n",
        "        label = \"😊 Happy Voice Detected!\" if prob > 0.5 else \"😐 Not a Happy Voice\"\n",
        "        confidence = f\"Confidence: {prob:.2f}\"\n",
        "        return label, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(\"🔍 Full traceback:\")\n",
        "        traceback.print_exc()\n",
        "        return f\"⚠️ Error: {str(e)}\", None\n"
      ],
      "metadata": {
        "id": "r1Iu6rBxBg2V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_audio(\"happy_sample.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnPelj_sBjCr",
        "outputId": "84aa6cb2-a529-4dc9-a805-f5562dbdad88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('😐 Not a Happy Voice', 'Confidence: 0.18')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Not Happy Sample:\", predict_audio(\"not_happy_sample.wav\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OREoUGdvBkON",
        "outputId": "f47c5ebb-db95-4531-d088-915a815d1ee7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Happy Sample: ('😐 Not a Happy Voice', 'Confidence: 0.37')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Check happy sample\n",
        "happy_audio, sr = librosa.load(\"happy_sample.wav\", sr=None)\n",
        "print(f\"Happy sample: Duration = {len(happy_audio)/sr:.2f}s, Sample Rate = {sr} Hz\")\n",
        "\n",
        "# Check sad sample\n",
        "sad_audio, sr = librosa.load(\"not_happy_sample.wav\", sr=None)\n",
        "print(f\"Sad sample: Duration = {len(sad_audio)/sr:.2f}s, Sample Rate = {sr} Hz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ0IXNaMDTSm",
        "outputId": "383e7b73-19ea-42d1-b54d-25a66da0042c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy sample: Duration = 1.00s, Sample Rate = 44100 Hz\n",
            "Sad sample: Duration = 1.00s, Sample Rate = 44100 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_audio(\"/content/ravdess_speech/Actor_18/03-01-03-01-02-02-18.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnRpG_kEW9T",
        "outputId": "f9e66c05-2570-4137-c918-8562f93740e5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('😊 Happy Voice Detected!', 'Confidence: 0.51')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_audio(\"/content/ravdess_speech/Actor_03/03-01-04-01-02-02-03.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-TrE4pEYz5",
        "outputId": "b5bb80cb-13a7-4325-b22a-d194f1db8b1f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('😐 Not a Happy Voice', 'Confidence: 0.01')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_audio(\"/content/ravdess_speech/Actor_18/03-01-08-02-02-02-18.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BW8efuIErpC",
        "outputId": "c9959c58-da18-4c85-de58-12aceddea156"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('😐 Not a Happy Voice', 'Confidence: 0.09')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_audio(\"/content/ravdess_speech/Actor_24/03-01-08-02-02-02-24.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC-vFY5uE5CK",
        "outputId": "2ced9f3b-4c97-4c61-a8a6-65de4532bd1c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('😐 Not a Happy Voice', 'Confidence: 0.01')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}